{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Follow the setup instructions to create the pipenv environment, then connect this notebook to the\n",
    "Python kernel in the \"`music-interpolation-...`\" environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from IPython.display import Audio\n",
    "from music_interpolation.encodec_interpolation import EncodecInterpolation\n",
    "\n",
    "AUDIO_A_PATH = \"../tests/data/house-equanimity-10s.mp3\"\n",
    "AUDIO_B_PATH = \"../tests/data/they-know-me-10s.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = EncodecInterpolation(device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: basic\n",
    "\n",
    "# Load the audio files into raw waveform numpy arrays\n",
    "audio_a, orig_sr_a = librosa.load(AUDIO_A_PATH, sr=None, mono=False)\n",
    "audio_b, orig_sr_b = librosa.load(AUDIO_B_PATH, sr=None, mono=False)\n",
    "\n",
    "# Manually resample (if needed) instead of at load time to enable the highest\n",
    "# quality resampler\n",
    "if orig_sr_a != interp.sampling_rate:\n",
    "    audio_a = librosa.resample(\n",
    "        audio_a, orig_sr=orig_sr_a, target_sr=interp.sampling_rate, res_type=\"soxr_vhq\"\n",
    "    )\n",
    "if orig_sr_b != interp.sampling_rate:\n",
    "    audio_b = librosa.resample(\n",
    "        audio_b, orig_sr=orig_sr_b, target_sr=interp.sampling_rate, res_type=\"soxr_vhq\"\n",
    "    )\n",
    "\n",
    "# Trim to the shorter of the two audio files\n",
    "duration = min(audio_a.shape[1], audio_b.shape[1])\n",
    "if audio_a.shape[1] > duration:\n",
    "    print(f\"Trimming audio_a from {audio_a.shape[1]} to {duration}\")\n",
    "    audio_a = audio_a[:, :duration]\n",
    "elif audio_b.shape[1] > duration:\n",
    "    print(f\"Trimming audio_b from {audio_b.shape[1]} to {duration}\")\n",
    "    audio_b = audio_b[:, :duration]\n",
    "\n",
    "Audio(audio_a, rate=interp.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(audio_b, rate=interp.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_c = interp.interpolate(audio_a, audio_b)  # pyright: ignore\n",
    "\n",
    "Audio(audio_c, rate=interp.sampling_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music-interpolation-CiJIWn5K",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
